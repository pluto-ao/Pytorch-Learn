# 1.大纲

- Pytorch 的数据读取机制( DataLoad 和 Dataset， 以一个人民币二分类的任务展开，通过代码调试去看逻辑和原理)；
- Pytorch 的图像预处理 transforms（图像增强，选择，自定义 transforms 等）；
- 总结梳理。

![image-20210511123326126](C:\Users\Pluto\AppData\Roaming\Typora\typora-user-images\image-20210511123326126.png)

# 2.数据读取机制

![图片](https://mmbiz.qpic.cn/mmbiz_png/210IyDic7rac9dtbepcdBibVo1KDD3icTYwJJaq7gMg5EHuynYic4hgYK1E6rjr9v8dXO82kGicfjicNcZ9zlsykqsqQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

##  2.1 DataLoader

### torch.utils.data.DataLoader()

构建可迭代的数据装载器, 我们在训练的时候，每一个 for 循环，每一次 iteration，就是从 DataLoader 中获取一个 batch_size 大小的数据的。

![image-20210511134725604](C:\Users\Pluto\AppData\Roaming\Typora\typora-user-images\image-20210511134725604.png)

- dataset: Dataset 类， 决定数据从哪读取以及如何读取
- bathsize: 批大小
- num_works: 是否多进程读取机制
- shuffle: 每个 epoch 是否乱序
- drop_last: 当样本数不能被 batchsize 整除时， 是否舍弃最后一批数据



要理解这个 drop_last， 首先，得先理解 Epoch， Iteration 和 Batchsize 的概念：

- Epoch：所有训练样本都已输入到模型中，称为一个 Epoch
- Iteration：一批样本输入到模型中，称为一个 Iteration
- Batchsize：批大小，决定一个 Epoch 有多少个 Iteration

##  2.2 Dataset

### torch.utils.data.Dataset()

Dataset 抽象类， 所有自定义的 Dataset 都需要继承它，并且必须复写 `__getitem__()` 这个类方法。

![图片](https://mmbiz.qpic.cn/mmbiz_png/210IyDic7rac9dtbepcdBibVo1KDD3icTYwSiaTYpZq4Hck6EmswIuT4diajpPV0p56u1Ig249GpJfVGDxNzIhicl8icA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

`__getitem__` 方法的是 Dataset 的核心，作用是接收一个索引，返回一个样本，看上面的函数，参数里面接收 index，然后我们需要编写究竟如何根据这个索引去读取我们的数据部分。

## **2.3 数据读取机制具体怎么用呢？**

人民币分类 数据读取部分

```python
#==========================================step 1/5 准备数据===============================

# 数据的路径
split_dir = os.path.join('data', 'rmb_split')
train_dir = os.path.join(split_dir, 'train')
valid_dir = os.path.join(split_dir, 'valid')

## transforms模块，进行数据预处理
norm_mean = [0.485, 0.456, 0.406]
norm_std = [0.229, 0.224, 0.225]

train_transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.RandomCrop(32, padding=4),
    transforms.ToTensor(),
    transforms.Normalize(norm_mean, norm_std),
])

valid_transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize(norm_mean, norm_std),
])

## 构建MyDataset实例
train_data = RMBDataset(data_dir=train_dir, transform=train_transform)
valid_data = RMBDataset(data_dir=valid_dir, transform=valid_transform)

# 构建DataLoader
train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)
valid_loader = DataLoader(dataset=valid_data, batch_size=BATCH_SIZE)

# print(train_loader)
```

我们从 `RMBDataset()` 开始， 这一句话里面的核心就是 RMBDataset，这个是我们自己写的一个类，继承了上面的抽象类 Dataset，并且重写了 `__getitem__()` 方法， 这个类的目的就是传入数据的路径，和预处理部分（看参数），然后给我们返回数据：

```python
class RMBDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        """
        rmb面额分类任务的Dataset
        :param data_dir: str, 数据集所在路径
        :param transform: torch.transform，数据预处理
        """
        self.label_name = {"1": 0, "100": 1}
        self.data_info = self.get_img_info(data_dir)  # data_info存储所有图片路径和标签，在DataLoader中通过index读取样本
        self.transform = transform

    def __getitem__(self, index):
        path_img, label = self.data_info[index]
        img = Image.open(path_img).convert('RGB')     # 0~255

        if self.transform is not None:
            img = self.transform(img)   # 在这里做transform，转为tensor等等

        return img, label

    def __len__(self):
        return len(self.data_info)

    @staticmethod
    def get_img_info(data_dir):
        data_info = list()
        for root, dirs, _ in os.walk(data_dir):
            # 遍历类别
            for sub_dir in dirs:
                img_names = os.listdir(os.path.join(root, sub_dir))
                img_names = list(filter(lambda x: x.endswith('.jpg'), img_names))

                # 遍历图片
                for i in range(len(img_names)):
                    img_name = img_names[i]
                    path_img = os.path.join(root, sub_dir, img_name)
                    label = rmb_label[sub_dir]
                    data_info.append((path_img, int(label)))

        return data_info
```

第一行我们拿到了一个样本的图片路径和标签。然后第二行就是去找到图片，然后转成RGB数值。第三行就是做了图片的数据预处理，最后返回了这张图片的张量形式和它的标签。

训练代码

```python
for epoch in range(MAX_EPOCH):
    loss_mean = 0.
    correct = 0.
    total = 0.

    net.train()

    for i, data in enumerate(train_loader):

        # forward
        inputs, labels = data
        outputs = net(inputs)

        # Compute loss
        optimizer.zero_grad()
        loss = criterion(outputs, labels)

        # backward
        loss.backward()

        # updata weights
        optimizer.step()
```

外循环表示的迭代 Epoch，也就是全部的训练样本喂入模型一次， 内循环表示的批次的循环，每一个 Epoch 中，都是一批批的喂入

![image-20210511155541594](C:\Users\Pluto\AppData\Roaming\Typora\typora-user-images\image-20210511155541594.png)

# 3.图像预处理 transforms



- torchvision.transforms: 常用的图像预处理方法, 比如标准化，中心化，旋转，翻转等操作
- trochvision.datasets: 常用的数据集的dataset实现， MNIST, CIFAR-10, ImageNet等
- torchvision.models: 常用的模型预训练, AlexNet, VGG, ResNet, GoogLeNet等。

## 3.1 二分类任务中用到的 transforms 的方法

- transforms.Compose方法是将一系列的transforms方法进行有序的组合包装，具体实现的时候，依次的用包装的方法对图像进行操作。
- transforms.Resize方法改变图像大小
- transforms.RandomCrop方法对图像进行裁剪（这个在训练集里面用，验证集就用不到了）
- transforms.ToTensor方法是将图像转换成张量，同时会进行归一化的一个操作，将张量的值从0-255转到0-1
- transforms.Normalize方法是将数据进行标准化

##  3.2 transforms 的其他图像增强方法

1. 数据增强 对**「训练集」**进行变换，使训练集更丰富，从而让模型更具**「泛化能力」**

2. 图像裁剪

3. - `transforms.CenterCrop(size)`: 图像中心裁剪图片, size是所需裁剪的图片尺寸，如果比原始图像大了， 会默认填充0。
   - `transforms.RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant)`:  从图片中位置随机裁剪出尺寸为size的图片， size是尺寸大小，padding设置填充大小（当为a， 上下左右均填充a个像素， 当为(a,b), 上下填充b个，左右填充a个，当为(a,b,c,d)， 左，上，右，下分别填充a,b,c,d个）， pad_if_need: 若图像小于设定的size, 则填充。padding_mode表示填充模型， 有4种，constant像素值由fill设定， edge像素值由图像边缘像素设定，reflect镜像填充， symmetric也是镜像填充， 这俩镜像是怎么做的看官方文档吧。镜像操作就类似于复制图片的一部分进行填充。
   - `transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(3/4, 4/3), interpolation)`: 随机大小，长宽比裁剪图片。scale表示随机裁剪面积比例，ratio随机长宽比， interpolation表示插值方法。
   - `FiveCrop, TenCrop`: 在图像的上下左右及中心裁剪出尺寸为size的5张图片，后者还在这5张图片的基础上再水平或者垂直镜像得到10张图片，具体使用这里就不整理了。

4. 图像的翻转和旋转

5. 1. `RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)`: 依概率水平或者垂直翻转图片， p表示翻转概率
   2. `RandomRotation(degrees, resample=False, expand=False, center=None)`:随机旋转图片， degrees表示旋转角度 ， resample表示重采样方法， expand表示是否扩大图片，以保持原图信息。

6. 图像变换

7. - `transforms.Pad(padding, fill=0, padding_mode='constant')`: 对图片边缘进行填充
   - `transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)`:调整亮度、对比度、饱和度和色相， 这个是比较实用的方法， brightness是亮度调节因子， contrast对比度参数， saturation饱和度参数， hue是色相因子。
   - `transfor.RandomGrayscale(num_output_channels, p=0.1)`: 依概率将图片转换为灰度图， 第一个参数是通道数， 只能1或3， p是概率值，转换为灰度图像的概率
   - `transforms.RandomAffine(degrees, translate=None, scale=None, shear=None, resample=False, fillcolor=0)`: 对图像进行仿射变换， 反射变换是二维的线性变换， 由五中基本原子变换构成，分别是旋转，平移，缩放，错切和翻转。degrees表示旋转角度， translate表示平移区间设置，scale表示缩放比例，fill_color填充颜色设置， shear表示错切
   - `transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)`: 这个也比较实用， 对图像进行随机遮挡， p概率值，scale遮挡区域的面积， ratio遮挡区域长宽比。随机遮挡有利于模型识别被遮挡的图片。value遮挡像素。**「这个是对张量进行操作，所以需要先转成张量才能做」**
   - `transforms.Lambda(lambd)`: 用户自定义的lambda方法， lambd是一个匿名函数。lambda [arg1 [, arg2...argn]]: expression
   - `.Resize, .ToTensor, .Normalize`: 这三个方法上面具体说过，在这里只是提一下子。

## **3.3 transforms 的选择操作**

1. `transforms.RandomChoice([transforms1, transforms2, transforms3])`: 从一系列transforms方法中随机选一个
2. `transforms.RandomApply([transforms1, transforms2, transforms3], p=0.5)`: 依据概率执行一组transforms操作
3. `transforms.RandomOrder([transforms1, transforms2, transforms3])`: 对一组transforms操作打乱顺序

##  3.4 自定义 transforms

下面给出一个自定义transforms的结构：

![图片](https://mmbiz.qpic.cn/mmbiz_png/210IyDic7rac9dtbepcdBibVo1KDD3icTYwxia0xMKUIVJgIJHu5bVJyoU0UpUYAbusJu0Acibdn3gyGkQup600NEiaw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

上面就是整个transforms的图像增强处理的技术了。但是实际工作中，最关键的还不是技术，而是战术，这些技术我们现在都知道了， 到时候用到的时候可以随时去查然后拿过来用。但是我们如何去选择图像增强的策略呢？ 这个才是重点。

数据增强策略原则：**「让训练集与测试集更接近」**。

- 空间位置上：可以选择平移
- 色彩上：灰度图，色彩抖动
- 形状：仿射变换
- 上下文场景：遮挡，填充